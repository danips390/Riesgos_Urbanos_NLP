{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search-tweets-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials\n",
    "\n",
    "# Cargar credenciales\n",
    "premium_search_args = load_credentials(\"./twitter_keys.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "\n",
    "# Lista de usuarios\n",
    "usuarios = [\n",
    "    'Cicmty', 'conagua_mx', 'elnortelocal', 'LoQuePasaenNL', 'eldelaconsty', 'camion_desde',\n",
    "    'metrorreynlofi1', 'MovilidadSN', 'SSP_Apodaca', 'PC_NuevoLeon', 'TodosSomosHLM',\n",
    "    'AtentosMTYSur', 'Apodaca_News', 'ArbSanJorge', 'SoyDeSanNicolas', 'abimaelsal',\n",
    "    'BomberosNL', 'nelvaldez', 'MAGS_SP', 'saz2000', 'DarkKnightMty', 'revistacodigo21',\n",
    "    'Mty_Leones', 'cesarmty', '911SanPedro', 'SSPCMonterrey', 'pc_mty', 'rayelizalder',\n",
    "    'Informativo3651', 'arualsanpedrogg', 'JulioCesarCano', 'nmasmonterrey', 'info7mty',\n",
    "    'ABCNoticiasMX', 'AsiEsMonterrey', 'GobSanNicolas', 'PortalElPunto',\n",
    "    'gob_Escobed', 'mtygob', 'joluisgarcia', 'visionmty1', 'QuePasaEnS', 'LCAlatorre',\n",
    "    'IdentidadNL', 'MtyFollow', 'ayd_monterrey', 'ComunidadMTY', 'municipiodegpe',\n",
    "    'CiudaDanaMtySur'\n",
    "]\n",
    "\n",
    "# Crear la regla de búsqueda con filtro de fechas para el año 2024\n",
    "rule = gen_rule_payload(\n",
    "    \" OR \".join([f\"from:{user}\" for user in usuarios]),  # Se arma la query con cada usuario\n",
    "    from_date=\"2024-01-01\", \n",
    "    to_date=\"2024-12-31\",\n",
    "    results_per_call=50\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda\n",
    "rs = ResultStream(rule_payload=rule, max_results=50, **premium_search_args)\n",
    "\n",
    "# Obtener resultados\n",
    "tweets = list(rs.stream())\n",
    "\n",
    "# Guardar los resultados en un archivo JSON\n",
    "with open('tweets_2024.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tweets, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Tweets de 2024 guardados en 'tweets_2024.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento con Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al obtener tweets para el usuario Cicmty: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario Cicmty\n",
      "Error al obtener tweets para el usuario conagua_mx: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario conagua_mx\n",
      "Error al obtener tweets para el usuario elnortelocal: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario elnortelocal\n",
      "Error al obtener tweets para el usuario LoQuePasaenNL: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario LoQuePasaenNL\n",
      "Error al obtener tweets para el usuario eldelaconsty: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario eldelaconsty\n",
      "Error al obtener tweets para el usuario camion_desde: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario camion_desde\n",
      "Error al obtener tweets para el usuario metrorreynlofi1: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario metrorreynlofi1\n",
      "Error al obtener tweets para el usuario MovilidadSN: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario MovilidadSN\n",
      "Error al obtener tweets para el usuario SSP_Apodaca: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario SSP_Apodaca\n",
      "Error al obtener tweets para el usuario PC_NuevoLeon: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario PC_NuevoLeon\n",
      "Error al obtener tweets para el usuario TodosSomosHLM: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario TodosSomosHLM\n",
      "Error al obtener tweets para el usuario AtentosMTYSur: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario AtentosMTYSur\n",
      "Error al obtener tweets para el usuario Apodaca_News: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario Apodaca_News\n",
      "Error al obtener tweets para el usuario ArbSanJorge: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario ArbSanJorge\n",
      "Error al obtener tweets para el usuario SoyDeSanNicolas: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario SoyDeSanNicolas\n",
      "Error al obtener tweets para el usuario abimaelsal: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario abimaelsal\n",
      "Error al obtener tweets para el usuario BomberosNL: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario BomberosNL\n",
      "Error al obtener tweets para el usuario nelvaldez: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario nelvaldez\n",
      "Error al obtener tweets para el usuario MAGS_SP: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario MAGS_SP\n",
      "Error al obtener tweets para el usuario saz2000: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario saz2000\n",
      "Error al obtener tweets para el usuario DarkKnightMty: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario DarkKnightMty\n",
      "Error al obtener tweets para el usuario revistacodigo21: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario revistacodigo21\n",
      "Error al obtener tweets para el usuario Mty_Leones: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario Mty_Leones\n",
      "Error al obtener tweets para el usuario cesarmty: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario cesarmty\n",
      "Error al obtener tweets para el usuario 911SanPedro: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario 911SanPedro\n",
      "Error al obtener tweets para el usuario SSPCMonterrey: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario SSPCMonterrey\n",
      "Error al obtener tweets para el usuario pc_mty: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario pc_mty\n",
      "Error al obtener tweets para el usuario rayelizalder: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario rayelizalder\n",
      "Error al obtener tweets para el usuario Informativo3651: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario Informativo3651\n",
      "Error al obtener tweets para el usuario arualsanpedrogg: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario arualsanpedrogg\n",
      "Error al obtener tweets para el usuario JulioCesarCano: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario JulioCesarCano\n",
      "Error al obtener tweets para el usuario nmasmonterrey: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario nmasmonterrey\n",
      "Error al obtener tweets para el usuario info7mty: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario info7mty\n",
      "Error al obtener tweets para el usuario ABCNoticiasMX: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario ABCNoticiasMX\n",
      "Error al obtener tweets para el usuario AsiEsMonterrey: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario AsiEsMonterrey\n",
      "Error al obtener tweets para el usuario GobSanNicolas: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario GobSanNicolas\n",
      "Error al obtener tweets para el usuario PortalElPunto: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario PortalElPunto\n",
      "Error al obtener tweets para el usuario gob_Escobed: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario gob_Escobed\n",
      "Error al obtener tweets para el usuario mtygob: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario mtygob\n",
      "Error al obtener tweets para el usuario joluisgarcia: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario joluisgarcia\n",
      "Error al obtener tweets para el usuario visionmty1: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario visionmty1\n",
      "Error al obtener tweets para el usuario QuePasaEnS: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario QuePasaEnS\n",
      "Error al obtener tweets para el usuario LCAlatorre: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario LCAlatorre\n",
      "Error al obtener tweets para el usuario IdentidadNL: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario IdentidadNL\n",
      "Error al obtener tweets para el usuario MtyFollow: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario MtyFollow\n",
      "Error al obtener tweets para el usuario ayd_monterrey: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario ayd_monterrey\n",
      "Error al obtener tweets para el usuario ComunidadMTY: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario ComunidadMTY\n",
      "Error al obtener tweets para el usuario municipiodegpe: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario municipiodegpe\n",
      "Error al obtener tweets para el usuario CiudaDanaMtySur: 401 Unauthorized\n",
      "Unauthorized\n",
      "Sin datos para procesar para el usuario CiudaDanaMtySur\n",
      "Tweets guardados en 'tweets_usuarios.json'\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "\n",
    "# Claves de autenticación\n",
    "BEARER_TOKEN = os.getenv(\"BEARER_TOKEN\")\n",
    "\n",
    "# Autenticación mediante Bearer Token\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# Lista de usuarios por sus nombres de usuario\n",
    "usuarios = [\n",
    "    'Cicmty', 'conagua_mx', 'elnortelocal', 'LoQuePasaenNL', 'eldelaconsty', 'camion_desde',\n",
    "    'metrorreynlofi1', 'MovilidadSN', 'SSP_Apodaca', 'PC_NuevoLeon', 'TodosSomosHLM',\n",
    "    'AtentosMTYSur', 'Apodaca_News', 'ArbSanJorge', 'SoyDeSanNicolas', 'abimaelsal',\n",
    "    'BomberosNL', 'nelvaldez', 'MAGS_SP', 'saz2000', 'DarkKnightMty', 'revistacodigo21',\n",
    "    'Mty_Leones', 'cesarmty', '911SanPedro', 'SSPCMonterrey', 'pc_mty', 'rayelizalder',\n",
    "    'Informativo3651', 'arualsanpedrogg', 'JulioCesarCano', 'nmasmonterrey', 'info7mty',\n",
    "    'ABCNoticiasMX', 'AsiEsMonterrey', 'GobSanNicolas', 'PortalElPunto',\n",
    "    'gob_Escobed', 'mtygob', 'joluisgarcia', 'visionmty1', 'QuePasaEnS', 'LCAlatorre',\n",
    "    'IdentidadNL', 'MtyFollow', 'ayd_monterrey', 'ComunidadMTY', 'municipiodegpe',\n",
    "    'CiudaDanaMtySur']\n",
    "\n",
    "# Función para obtener los tweets de un usuario limitados a 2024\n",
    "def get_user_tweets(username, count):\n",
    "    try:\n",
    "        # Obtener el ID del usuario\n",
    "        user = client.get_user(username=username)\n",
    "        user_id = user.data.id\n",
    "        \n",
    "        # Limitar los tweets a partir de enero de 2024\n",
    "        start_time = datetime(2024, 1, 1).isoformat() + 'Z'\n",
    "        \n",
    "        # Obtener los tweets del usuario con los campos necesarios\n",
    "        tweets = client.get_users_tweets(\n",
    "            id=user_id,\n",
    "            max_results=count,\n",
    "            start_time=start_time,\n",
    "            tweet_fields=['created_at', 'public_metrics', 'entities', 'geo']\n",
    "        )\n",
    "        \n",
    "        # Verificar si se obtuvieron tweets correctamente\n",
    "        if tweets.data:\n",
    "            print(f\"Tweets obtenidos correctamente para el usuario {username}\")\n",
    "            return tweets.data\n",
    "        else:\n",
    "            print(f\"No se encontraron tweets para el usuario {username}\")\n",
    "            return None\n",
    "\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"Error al obtener tweets para el usuario {username}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Manejo de Rate Limits y revisión de éxito\n",
    "def get_tweets_multiple_users(usuarios, count):\n",
    "    # Definir la zona horaria de Monterrey\n",
    "    zona_horaria_monterrey = pytz.timezone('America/Monterrey')\n",
    "    \n",
    "    tweets_por_usuario = {}\n",
    "    for usuario in usuarios:\n",
    "        try:\n",
    "            tweets = get_user_tweets(usuario, count)\n",
    "            if tweets:\n",
    "                # Guardar 'created_at', 'public_metrics', 'entities' y 'geo' de cada tweet\n",
    "                tweets_por_usuario[usuario] = [\n",
    "                    {\n",
    "                        'username': usuario,\n",
    "                        'created_at': tweet.created_at,\n",
    "                        'public_metrics': tweet.public_metrics,\n",
    "                        'entities': tweet.entities,\n",
    "                        'geo': tweet.geo\n",
    "                    }\n",
    "                    for tweet in tweets\n",
    "                ]\n",
    "                print(f\"Datos procesados correctamente para el usuario {usuario}\")\n",
    "            else:\n",
    "                print(f\"Sin datos para procesar para el usuario {usuario}\")\n",
    "\n",
    "        except tweepy.TooManyRequests:\n",
    "            # Obtener la hora actual en la zona horaria de Monterrey cuando se detecta el rate limit\n",
    "            hora_actual_monterrey = datetime.now(zona_horaria_monterrey).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"Rate limit alcanzado a las {hora_actual_monterrey}. Esperando 15 minutos...\")\n",
    "            time.sleep(900)  # Pausa de 15 minutos para respetar el rate limit\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error inesperado para el usuario {usuario}: {e}\")\n",
    "    \n",
    "    return tweets_por_usuario\n",
    "\n",
    "# Obtener los tweets de los usuarios\n",
    "tweets_por_usuario = get_tweets_multiple_users(usuarios, 50)\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "with open('tweets_usuarios.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['username', 'created_at', 'retweet_count', 'reply_count', 'like_count', 'quote_count', 'entities', 'geo']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for usuario, tweets in tweets_por_usuario.items():\n",
    "        for tweet in tweets:\n",
    "            writer.writerow({\n",
    "                'username': usuario,\n",
    "                'created_at': tweet['created_at'],\n",
    "                'retweet_count': tweet['public_metrics']['retweet_count'],\n",
    "                'reply_count': tweet['public_metrics']['reply_count'],\n",
    "                'like_count': tweet['public_metrics']['like_count'],\n",
    "                'quote_count': tweet['public_metrics']['quote_count'],\n",
    "                'entities': tweet['entities'],\n",
    "                'geo': tweet['geo']\n",
    "            })\n",
    "\n",
    "print(\"Tweets guardados en 'tweets_usuarios.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento con twitter_scrapper v 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al obtener tweets para el usuario Cicmty: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario conagua_mx: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario elnortelocal: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario LoQuePasaenNL: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario eldelaconsty: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario camion_desde: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario metrorreynlofi1: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario MovilidadSN: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario SSP_Apodaca: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario PC_NuevoLeon: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario TodosSomosHLM: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario AtentosMTYSur: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario Apodaca_News: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario ArbSanJorge: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario SoyDeSanNicolas: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario abimaelsal: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario BomberosNL: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario nelvaldez: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario MAGS_SP: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario saz2000: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario DarkKnightMty: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario revistacodigo21: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario Mty_Leones: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario cesarmty: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario 911SanPedro: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario SSPCMonterrey: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario pc_mty: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario rayelizalder: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario Informativo3651: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario arualsanpedrogg: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario JulioCesarCano: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario nmasmonterrey: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario info7mty: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario ABCNoticiasMX: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario AsiEsMonterrey: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario GobSanNicolas: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario PortalElPunto: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario gob_Escobed: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario mtygob: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario joluisgarcia: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario visionmty1: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario QuePasaEnS: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario LCAlatorre: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario IdentidadNL: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario MtyFollow: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario ayd_monterrey: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario ComunidadMTY: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario municipiodegpe: Expecting value: line 1 column 1 (char 0)\n",
      "Error al obtener tweets para el usuario CiudaDanaMtySur: Expecting value: line 1 column 1 (char 0)\n",
      "Tweets guardados en 'tweets_usuarios.json'\n"
     ]
    }
   ],
   "source": [
    "from twitter_scraper import get_tweets\n",
    "import json\n",
    "\n",
    "# Lista de usuarios\n",
    "usuarios = [\n",
    "    'Cicmty', 'conagua_mx', 'elnortelocal', 'LoQuePasaenNL', 'eldelaconsty', 'camion_desde',\n",
    "    'metrorreynlofi1', 'MovilidadSN', 'SSP_Apodaca', 'PC_NuevoLeon', 'TodosSomosHLM',\n",
    "    'AtentosMTYSur', 'Apodaca_News', 'ArbSanJorge', 'SoyDeSanNicolas', 'abimaelsal',\n",
    "    'BomberosNL', 'nelvaldez', 'MAGS_SP', 'saz2000', 'DarkKnightMty', 'revistacodigo21',\n",
    "    'Mty_Leones', 'cesarmty', '911SanPedro', 'SSPCMonterrey', 'pc_mty', 'rayelizalder',\n",
    "    'Informativo3651', 'arualsanpedrogg', 'JulioCesarCano', 'nmasmonterrey', 'info7mty',\n",
    "    'ABCNoticiasMX', 'AsiEsMonterrey', 'GobSanNicolas', 'PortalElPunto',\n",
    "    'gob_Escobed', 'mtygob', 'joluisgarcia', 'visionmty1', 'QuePasaEnS', 'LCAlatorre',\n",
    "    'IdentidadNL', 'MtyFollow', 'ayd_monterrey', 'ComunidadMTY', 'municipiodegpe',\n",
    "    'CiudaDanaMtySur'\n",
    "]\n",
    "\n",
    "# Obtener los tweets de los usuarios\n",
    "tweets_por_usuario = {}\n",
    "\n",
    "for usuario in usuarios:\n",
    "    try:\n",
    "        # Obtener los tweets del usuario\n",
    "        tweets = get_tweets(usuario, pages=1)\n",
    "        \n",
    "        # Guardar 'time' y 'text' de cada tweet\n",
    "        tweets_por_usuario[usuario] = [\n",
    "            {\n",
    "                'time': tweet['time'],\n",
    "                'text': tweet['text']\n",
    "            }\n",
    "            for tweet in tweets\n",
    "        ]\n",
    "        print(f\"Tweets obtenidos correctamente para el usuario {usuario}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener tweets para el usuario {usuario}: {e}\")\n",
    "\n",
    "# Guardar los resultados en un archivo JSON\n",
    "with open('tweets_usuarios.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tweets_por_usuario, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Tweets guardados en 'tweets_usuarios.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento con ScrapFly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playwright\n",
      "  Downloading playwright-1.47.0-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jmespath in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.1)\n",
      "Collecting scrapfly-sdk\n",
      "  Downloading scrapfly_sdk-0.8.18-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: greenlet==3.0.3 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from playwright) (3.0.3)\n",
      "Collecting pyee==12.0.0 (from playwright)\n",
      "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyee==12.0.0->playwright) (4.9.0)\n",
      "Requirement already satisfied: decorator>=4.2.0 in c:\\users\\aesca\\appdata\\roaming\\python\\python311\\site-packages (from scrapfly-sdk) (5.1.1)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapfly-sdk) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\aesca\\appdata\\roaming\\python\\python311\\site-packages (from scrapfly-sdk) (2.8.2)\n",
      "Requirement already satisfied: loguru>=0.5 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapfly-sdk) (0.7.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapfly-sdk) (1.26.18)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapfly-sdk) (2.2.1)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\aesca\\appdata\\roaming\\python\\python311\\site-packages (from loguru>=0.5->scrapfly-sdk) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from loguru>=0.5->scrapfly-sdk) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aesca\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3.0.0,>=2.1->scrapfly-sdk) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.0->scrapfly-sdk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.0->scrapfly-sdk) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aesca\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.0->scrapfly-sdk) (2023.11.17)\n",
      "Downloading playwright-1.47.0-py3-none-win_amd64.whl (29.9 MB)\n",
      "   ---------------------------------------- 0.0/29.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/29.9 MB 14.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 6.3/29.9 MB 17.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 10.0/29.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 13.6/29.9 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.3/29.9 MB 16.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 19.4/29.9 MB 16.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 22.3/29.9 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 25.4/29.9 MB 15.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.6/29.9 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 29.9/29.9 MB 15.3 MB/s eta 0:00:00\n",
      "Downloading pyee-12.0.0-py3-none-any.whl (14 kB)\n",
      "Downloading scrapfly_sdk-0.8.18-py3-none-any.whl (39 kB)\n",
      "Installing collected packages: pyee, scrapfly-sdk, playwright\n",
      "  Attempting uninstall: pyee\n",
      "    Found existing installation: pyee 11.1.1\n",
      "    Uninstalling pyee-11.1.1:\n",
      "      Successfully uninstalled pyee-11.1.1\n",
      "Successfully installed playwright-1.47.0 pyee-12.0.0 scrapfly-sdk-0.8.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 2.0.0 requires pyee<12.0.0,>=11.0.0, but you have pyee 12.0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install playwright jmespath scrapfly-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento con twscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from twscrape import API, gather\n",
    "from twscrape.logger import set_log_level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

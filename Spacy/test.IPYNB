{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Apple is looking at buying U.K. startup for $1 bil...\" with entities \"[(0, 5, 'ORG'), (27, 31, 'GPE'), (44, 52, 'DINERO'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 0.048798730614108166}\n",
      "Losses {'ner': 0.0012802985675565751}\n",
      "Losses {'ner': 0.0012185646629109567}\n",
      "Losses {'ner': 8.157046629099546e-07}\n",
      "Losses {'ner': 0.00019530642358557673}\n",
      "Losses {'ner': 4.450582334967897e-05}\n",
      "Losses {'ner': 0.18067293079781294}\n",
      "Losses {'ner': 0.14045198610014878}\n",
      "Losses {'ner': 4.890000652918326e-06}\n",
      "Losses {'ner': 3.638184456769861e-06}\n",
      "Losses {'ner': 2.0545707631427339e-07}\n",
      "Losses {'ner': 4.450217688959262e-07}\n",
      "Losses {'ner': 0.022578261460264357}\n",
      "Losses {'ner': 2.6598637096896998e-08}\n",
      "Losses {'ner': 2.61504306772052e-09}\n",
      "Losses {'ner': 0.0011053132880319335}\n",
      "Losses {'ner': 4.216021439873095e-09}\n",
      "Losses {'ner': 7.328441062222972e-08}\n",
      "Losses {'ner': 2.001467420061342e-07}\n",
      "Losses {'ner': 8.343289376522011e-08}\n",
      "Losses {'ner': 1.2146562746976504e-07}\n",
      "Losses {'ner': 5.874626488266721e-07}\n",
      "Losses {'ner': 5.27352229570635e-10}\n",
      "Losses {'ner': 5.59730097535646e-08}\n",
      "Losses {'ner': 0.004377023872811205}\n",
      "Losses {'ner': 6.8776953653842716e-09}\n",
      "Losses {'ner': 9.704834059095288e-10}\n",
      "Losses {'ner': 1.6915782957816096e-11}\n",
      "Losses {'ner': 2.542242826414575e-10}\n",
      "Losses {'ner': 1.0732121551448718e-09}\n",
      "Losses {'ner': 6.417707045085857e-10}\n",
      "Losses {'ner': 1.1884302382129633e-08}\n",
      "Losses {'ner': 2.390270421861135e-10}\n",
      "Losses {'ner': 7.317823900480859e-09}\n",
      "Losses {'ner': 1.7588802718166624e-08}\n",
      "Losses {'ner': 1.1211308444259256e-08}\n",
      "Losses {'ner': 7.541526738792554e-09}\n",
      "Losses {'ner': 1.1318090964735965e-09}\n",
      "Losses {'ner': 3.2733830989639268e-09}\n",
      "Losses {'ner': 1.7089473390336123e-07}\n",
      "Losses {'ner': 1.7112477688866292e-07}\n",
      "Losses {'ner': 3.284967566144555e-10}\n",
      "Losses {'ner': 7.26629276988599e-10}\n",
      "Losses {'ner': 1.3007144690366915e-07}\n",
      "Losses {'ner': 2.1527959347905312e-10}\n",
      "Losses {'ner': 8.228493345921401e-09}\n",
      "Losses {'ner': 1.4990179469494078e-10}\n",
      "Losses {'ner': 9.390723757674322e-12}\n",
      "Losses {'ner': 1.0841426783484713e-11}\n",
      "Losses {'ner': 2.8176881120795467e-10}\n",
      "Losses {'ner': 1.5604983513607945e-07}\n",
      "Losses {'ner': 3.0558611764805406e-11}\n",
      "Losses {'ner': 6.850093092816041e-06}\n",
      "Losses {'ner': 9.013813692669581e-12}\n",
      "Losses {'ner': 2.0139680555186128e-10}\n",
      "Losses {'ner': 6.838700633822128e-12}\n",
      "Losses {'ner': 5.577874464193583e-11}\n",
      "Losses {'ner': 1.7047483105139294e-08}\n",
      "Losses {'ner': 1.089829984893199e-07}\n",
      "Losses {'ner': 6.668497333859278e-08}\n",
      "Losses {'ner': 3.930863071554901e-11}\n",
      "Losses {'ner': 1.96020044861699e-11}\n",
      "Losses {'ner': 3.083388604587737e-11}\n",
      "Losses {'ner': 4.178505253201155e-10}\n",
      "Losses {'ner': 8.986751548960905e-11}\n",
      "Losses {'ner': 3.542520324849344e-11}\n",
      "Losses {'ner': 3.986463988341274e-09}\n",
      "Losses {'ner': 1.716614885964084e-08}\n",
      "Losses {'ner': 6.649386950883165e-12}\n",
      "Losses {'ner': 3.698900732372887e-10}\n",
      "Losses {'ner': 1.593462048120093e-10}\n",
      "Losses {'ner': 1.8144391763534376e-10}\n",
      "Losses {'ner': 5.541290173082261e-11}\n",
      "Losses {'ner': 4.4984642986887866e-10}\n",
      "Losses {'ner': 5.697135112321491e-08}\n",
      "Losses {'ner': 2.0164748798124277e-11}\n",
      "Losses {'ner': 1.6424153544493385e-09}\n",
      "Losses {'ner': 2.305110270909039e-08}\n",
      "Losses {'ner': 5.570128282505321e-11}\n",
      "Losses {'ner': 3.8186819772028544e-11}\n",
      "Losses {'ner': 8.081996159961699e-09}\n",
      "Losses {'ner': 5.834851582537529e-12}\n",
      "Losses {'ner': 1.1683260101576574e-07}\n",
      "Losses {'ner': 4.715430427859744e-10}\n",
      "Losses {'ner': 1.5047906574437275e-10}\n",
      "Losses {'ner': 1.1959914598412546e-12}\n",
      "Losses {'ner': 7.932856246041034e-09}\n",
      "Losses {'ner': 2.3543620441173985e-07}\n",
      "Losses {'ner': 1.7398002706386946e-11}\n",
      "Losses {'ner': 1.171612337559957e-10}\n",
      "Losses {'ner': 4.2403756231714905e-10}\n",
      "Losses {'ner': 1.2657741841579128e-09}\n",
      "Losses {'ner': 2.5119594637025574e-09}\n",
      "Losses {'ner': 2.024061958247384e-09}\n",
      "Losses {'ner': 2.4522872511902764e-11}\n",
      "Losses {'ner': 8.840394901168617e-07}\n",
      "Losses {'ner': 4.944000529289417e-07}\n",
      "Losses {'ner': 1.5653547615898267e-09}\n",
      "Losses {'ner': 2.1194139413958536e-09}\n",
      "Losses {'ner': 2.8396581680322625e-10}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Cargar el modelo base\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Añadir la etiqueta si no existe en el modelo\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(\"DINERO\")  # Ejemplo de una nueva etiqueta\n",
    "\n",
    "# Datos de entrenamiento\n",
    "TRAIN_DATA = [\n",
    "    (\"Apple is looking at buying U.K. startup for $1 billion\", {\n",
    "        \"entities\": [(0, 5, \"ORG\"), (27, 31, \"GPE\"), (44, 52, \"DINERO\")]\n",
    "    }),\n",
    "    (\"San Francisco considers banning sidewalk delivery robots\", {\n",
    "        \"entities\": [(0, 13, \"GPE\")]\n",
    "    }),\n",
    "    # Más ejemplos...\n",
    "]\n",
    "\n",
    "# Desactivar otros componentes del pipeline\n",
    "pipe_exceptions = [\"ner\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# Entrenar el modelo\n",
    "with nlp.disable_pipes(*unaffected_pipes):  # Solo entrenar NER\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(100):  # Número de iteraciones\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # Lote a lote (minibatch)\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            for text, annotations in batch:\n",
    "                # Crear un objeto Example\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], sgd=optimizer, drop=0.35, losses=losses)\n",
    "        print(\"Losses\", losses)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "nlp.to_disk(\"path_to_save_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo desde el disco\n",
    "nlp = spacy.load(\"path_to_save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "London GPE\n",
      "$2 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de texto para probar el modelo\n",
    "test_text = \"Apple is buying a startup in London for $2 billion\"\n",
    "\n",
    "# Procesar el texto con el modelo\n",
    "doc = nlp(test_text)\n",
    "\n",
    "# Mostrar las entidades detectadas\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar_tweet(tweet, calles, colonias):\n",
    "    entities = []\n",
    "    for calle in calles:\n",
    "        start = tweet.find(calle)\n",
    "        if start != -1:\n",
    "            end = start + len(calle)\n",
    "            entities.append((start, end, \"CALLE\"))\n",
    "    \n",
    "    for colonia in colonias:\n",
    "        start = tweet.find(colonia)\n",
    "        if start != -1:\n",
    "            end = start + len(colonia)\n",
    "            entities.append((start, end, \"COLONIA\"))\n",
    "\n",
    "    return (tweet, {\"entities\": entities})\n",
    "\n",
    "# Ejemplo de uso\n",
    "calles = [\"Insurgentes\", \"Reforma\", \"Chapultepec\"]\n",
    "colonias = [\"Roma\", \"Condesa\", \"Polanco\"]\n",
    "tweet = \"Vivo en la calle Reforma en la colonia Condesa\"\n",
    "\n",
    "training_data = [etiquetar_tweet(tweet, calles, colonias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Vivo en la calle Reforma en la colonia Condesa',\n",
       "  {'entities': [(17, 24, 'CALLE'), (39, 46, 'COLONIA')]})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La frase más cercana encontrada es: 'snta lucia.' con una puntuación promedio de 94.50\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Función para tokenizar los textos\n",
    "def tokenize_function(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "# Inicializar el tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Palabra objetivo (puede ser más de una palabra)\n",
    "target_word = \"santa lucia\"\n",
    "\n",
    "# Texto del que quieres extraer y comparar palabras\n",
    "text = \"Estamos celebrando la festividad de snta luci, pero algunos dicen que es o sant lucia.\"\n",
    "\n",
    "# Tokenizar el texto en palabras\n",
    "tokens = tokenize_function(text)\n",
    "\n",
    "# Convertir los tokens nuevamente a texto para compararlos\n",
    "tokenized_words = tokenizer.convert_tokens_to_string(tokens).split()\n",
    "\n",
    "# Dividir la palabra objetivo en partes\n",
    "target_tokens = target_word.split()\n",
    "\n",
    "# Buscar coincidencias para cada token de la palabra objetivo\n",
    "matches = []\n",
    "for target_token in target_tokens:\n",
    "    best_match = process.extractOne(target_token, tokenized_words)\n",
    "    matches.append(best_match)\n",
    "\n",
    "# Calcular la puntuación promedio de las coincidencias\n",
    "average_score = sum(match[1] for match in matches) / len(matches)\n",
    "\n",
    "# Encontrar las palabras originales en el texto\n",
    "original_words = []\n",
    "for match in matches:\n",
    "    best_match_token = match[0]\n",
    "    for word in text.split():\n",
    "        if best_match_token in word:\n",
    "            original_words.append(word)\n",
    "            break\n",
    "\n",
    "# Unir las palabras originales para obtener la frase final\n",
    "matched_phrase = ' '.join(original_words)\n",
    "\n",
    "print(f\"La frase más cercana encontrada es: '{matched_phrase}' con una puntuación promedio de {average_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La frase más cercana encontrada es: 'snta luci,' con una puntuación promedio de 89.00\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Función para tokenizar los textos\n",
    "def tokenize_function(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "# Inicializar el tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Palabra objetivo (puede ser más de una palabra)\n",
    "target_word = \"santa lucia\"\n",
    "\n",
    "# Texto del que quieres extraer y comparar palabras\n",
    "text = \"Estamos celebrando la festividad de snta luci, pero algunos dicen que es o sant lucia.\"\n",
    "\n",
    "# Tokenizar el texto en palabras\n",
    "tokens = tokenize_function(text)\n",
    "\n",
    "# Convertir los tokens nuevamente a texto para compararlos\n",
    "tokenized_words = tokenizer.convert_tokens_to_string(tokens).split()\n",
    "\n",
    "# Dividir la palabra objetivo en partes\n",
    "target_tokens = target_word.split()\n",
    "\n",
    "# Buscar coincidencia para la primera token\n",
    "first_match = process.extractOne(target_tokens[0], tokenized_words)\n",
    "best_match_token1 = first_match[0]\n",
    "position1 = tokenized_words.index(best_match_token1)\n",
    "\n",
    "# Encontrar las palabras originales en el texto para la primera token\n",
    "original_word1 = \"\"\n",
    "for word in text.split():\n",
    "    if best_match_token1 in word:\n",
    "        original_word1 = word\n",
    "        break\n",
    "\n",
    "# Buscar coincidencia para la segunda token cercana a la primera\n",
    "second_match = None\n",
    "for match in process.extract(target_tokens[1], tokenized_words, limit=5):\n",
    "    best_match_token2 = match[0]\n",
    "    position2 = tokenized_words.index(best_match_token2)\n",
    "    if abs(position2 - position1) <= len(target_word.split()):\n",
    "        second_match = match\n",
    "        break\n",
    "\n",
    "# Si no se encuentra una coincidencia cercana para la segunda token\n",
    "if second_match is None:\n",
    "    # Buscar la mejor coincidencia sin importar la proximidad\n",
    "    second_match = process.extractOne(target_tokens[1], tokenized_words)\n",
    "    best_match_token2 = second_match[0]\n",
    "    position2 = tokenized_words.index(best_match_token2)\n",
    "\n",
    "# Encontrar las palabras originales en el texto para la segunda token\n",
    "original_word2 = \"\"\n",
    "for word in text.split():\n",
    "    if best_match_token2 in word:\n",
    "        original_word2 = word\n",
    "        break\n",
    "\n",
    "# Unir las palabras originales para obtener la frase final\n",
    "matched_phrase = f\"{original_word1} {original_word2}\"\n",
    "average_score = (first_match[1] + second_match[1]) / 2\n",
    "\n",
    "print(f\"La frase más cercana encontrada es: '{matched_phrase}' con una puntuación promedio de {average_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La frase más cercana encontrada es: 'San P' con una puntuación promedio de 95.00\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Función para tokenizar los textos\n",
    "def tokenize_function(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "# Inicializar el tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Palabra objetivo (puede ser más de una palabra)\n",
    "target_word = \"San Pedro Garza García\"\n",
    "\n",
    "# Texto del que quieres extraer y comparar palabras\n",
    "text = \"Voy a ir a San P al otro lado de la loma, mañana\"\n",
    "\n",
    "# Tokenizar el texto en palabras\n",
    "tokens = tokenize_function(text)\n",
    "\n",
    "# Convertir los tokens nuevamente a texto para compararlos\n",
    "tokenized_words = tokenizer.convert_tokens_to_string(tokens).split()\n",
    "\n",
    "# Dividir la palabra objetivo en partes\n",
    "target_tokens = target_word.split()\n",
    "\n",
    "# Verificar si el texto tiene suficientes palabras tokenizadas\n",
    "if len(tokenized_words) < len(target_tokens):\n",
    "    print(\"El texto no tiene suficientes palabras para comparar con la palabra objetivo.\")\n",
    "else:\n",
    "    # Buscar coincidencia para la primera token\n",
    "    first_match = process.extractOne(target_tokens[0], tokenized_words)\n",
    "    best_match_token1 = first_match[0]\n",
    "    position1 = tokenized_words.index(best_match_token1)\n",
    "\n",
    "    # Encontrar las palabras originales en el texto para la primera token\n",
    "    original_word1 = \"\"\n",
    "    for word in text.split():\n",
    "        if best_match_token1.lower() in word.lower():\n",
    "            original_word1 = word\n",
    "            break\n",
    "\n",
    "    # Buscar coincidencia para la segunda token cercana a la primera (si existe)\n",
    "    if len(target_tokens) > 1:\n",
    "        second_match = None\n",
    "        for match in process.extract(target_tokens[1], tokenized_words, limit=5):\n",
    "            best_match_token2 = match[0]\n",
    "            position2 = tokenized_words.index(best_match_token2)\n",
    "            if abs(position2 - position1) <= len(target_word.split()):\n",
    "                second_match = match\n",
    "                break\n",
    "\n",
    "        # Si no se encuentra una coincidencia cercana para la segunda token\n",
    "        if second_match is None:\n",
    "            # Buscar la mejor coincidencia sin importar la proximidad\n",
    "            second_match = process.extractOne(target_tokens[1], tokenized_words)\n",
    "            best_match_token2 = second_match[0]\n",
    "            position2 = tokenized_words.index(best_match_token2)\n",
    "\n",
    "        # Encontrar las palabras originales en el texto para la segunda token\n",
    "        original_word2 = \"\"\n",
    "        for word in text.split():\n",
    "            if best_match_token2.lower() in word.lower():\n",
    "                original_word2 = word\n",
    "                break\n",
    "\n",
    "        # Unir las palabras originales para obtener la frase final\n",
    "        matched_phrase = f\"{original_word1} {original_word2}\".strip()\n",
    "        average_score = (first_match[1] + second_match[1]) / 2\n",
    "    else:\n",
    "        matched_phrase = original_word1\n",
    "        average_score = first_match[1]\n",
    "\n",
    "    if matched_phrase:\n",
    "        print(f\"La frase más cercana encontrada es: '{matched_phrase}' con una puntuación promedio de {average_score:.2f}\")\n",
    "    else:\n",
    "        print(\"No se encontró una coincidencia adecuada en el texto.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_accents_and_punctuation(text):\n",
    "    # Eliminar acentos\n",
    "    text = ''.join(\n",
    "        (c for c in unicodedata.normalize('NFD', text)\n",
    "         if unicodedata.category(c) != 'Mn')\n",
    "    )\n",
    "    # Eliminar signos de puntuación\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Aplicar la función a todo el DataFrame\n",
    "df1 = pd.read_csv('tweets_classified.csv')\n",
    "df2 = pd.read_csv('calles_colonias_monterrey.csv')\n",
    "\n",
    "tweets_df = df1.applymap(lambda x: remove_accents_and_punctuation(x) if isinstance(x, str) else x)\n",
    "calles_df = df2.applymap(lambda x: remove_accents_and_punctuation(x) if isinstance(x, str) else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "c:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0: 'cuidadodelagua fuga de agua limpia en un domicilio en olmos entre av potrero de anahuac y encinos col potrero anahuac sannicolas via enriquemgo cc aydmonterrey kmgn'\n",
      "Mejor coincidencia: 'anahuac' usando 'Anahuac' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 1: No se encontró una coincidencia adecuada.\n",
      "\n",
      "Tweet 2: 'luego de las lluvias torrenciales registradas en campeche se apoya a la poblacion de las zonas bajas inundadas ademas se bombea agua sobre la autopista champotoncampeche en el cruce del arroyo siho'\n",
      "Mejor coincidencia: 'del el' usando 'Del Reloj' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 3: 'un canal de bajapresion en la sierra madre occidental y centro de provocara lluvias torrenciales en gro oax pue y ver intensas en camp tamps chis col hgo jal mich qroo slp tab y yuc muy fuertes en edomex gto mor nay nl qro y tlax'\n",
      "Mejor coincidencia: 'sierra en' usando 'Sierra Morena' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 4: 'se preven lluvias puntuales torrenciales en guerrero oaxaca puebla y veracruz en las proximas horas mas informacion en'\n",
      "Mejor coincidencia: 'veracruz' usando 'Veracruz' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 5: 'como medida preventiva ante las lluvias que sigue generando alberto ahora como bajapresion remanente a las h se incremento la extraccion de ms a ms por vertedor controlado en la presa la boca se encuentra al de llenado con ingresos de ms'\n",
      "Mejor coincidencia: 'ante' usando 'Nantes' con una puntuación promedio de 90.00\n",
      "\n",
      "Tweet 6: 'ademas se preven lluvias intensas en durango guanajuato hidalgo nayarit queretaro y zacatecas muy fuertes en aguascalientes campeche chihuahua colima guerrero jalisco michoacan quintana roo y sinaloa asi como fuertes en yucatan'\n",
      "Mejor coincidencia: 'michoacan' usando 'Michoacan' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 7: 'aunque alberto ya se disipo es preciso no bajar la guardia porque sus remanentes siguen provocando lluvias considerables el smnmx informa que durante esta noche y madrugada habra lluvias torrenciales en chiapas coahuila nl oax pue slp tamaulipas y veracruz'\n",
      "Mejor coincidencia: 'veracruz' usando 'Veracruz' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 8: 'se pronostican lluvias torrenciales para coahuila nuevoleon oaxaca puebla sanluispotosi tamaulipas y veracruz mas informacion en'\n",
      "Mejor coincidencia: 'veracruz' usando 'Veracruz' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 9: 'como medida preventiva ante las lluvias que genera la bajapresion remanente de alberto a las hrs se incremento la extraccion en la presa la boca pasando de ms a ms por vertedor controlado actualmente tiene un de llenado con ingresos de ms'\n",
      "Mejor coincidencia: 'ante' usando 'Nantes' con una puntuación promedio de 90.00\n",
      "\n",
      "Tweet 10: 'como medida preventiva ante las lluvias que sigue generando alberto ahora como bajapresion remanente a las horas se incremento la extraccion de ms a ms por vertedor controlado en la presa la boca se encuentra al de llenado con ingresos de ms'\n",
      "Mejor coincidencia: 'ante' usando 'Nantes' con una puntuación promedio de 90.00\n",
      "\n",
      "Tweet 11: No se encontró una coincidencia adecuada.\n",
      "\n",
      "Tweet 12: 'con personal y equipo especializado el organismo de cuenca aguas del valledemexico de la conaguamx concluyo de forma anticipada a lo inicialmente previsto las reparaciones de la fuga presentada en la planta de bombeo numero del sistema cutzamala'\n",
      "Mejor coincidencia: 'del con' usando 'Del Halcon' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 13: 'comunicado antes de lo programado se concluye reparacion de fuga en la planta de bombeo del sistema cutzamala mas informacion en'\n",
      "Mejor coincidencia: 'del en' usando 'Del Penon' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 14: 'avisometeorologico alberto se ubica muy proximo a las costas de tamaulipas y veracruz y ocasiona lluvias en gran parte de mexico mas informacion en'\n",
      "Mejor coincidencia: 'veracruz' usando 'Veracruz' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 15: 'su amplia circulacion produce lluvias extraordinarias en nuevo leon tamaulipas san luis potosi veracruz hidalgo y puebla lluvias torrenciales en coahuila lluvias intensas en zacatecas queretaro oaxaca chiapas tabasco campeche y quintana roo'\n",
      "Mejor coincidencia: 'quintana roo' usando 'Quintana Roo' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 16: 'debido al paso de la tormentatropical alberto se pronostican lluvias y vientos importantes en campeche chiapas coahuila guanajuato hidalgo nuevo leon oaxaca puebla queretaro quintana roo san luis potosi tabasco tamaulipas veracruz y yucatan'\n",
      "Mejor coincidencia: 'quintana roo' usando 'Quintana Roo' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 17: 'comunicado ante paso del ciclon alberto es necesario extremar precauciones por lluvia viento y oleaje gobiernomx mas informacion en'\n",
      "Mejor coincidencia: 'ante' usando 'Nantes' con una puntuación promedio de 90.00\n",
      "\n",
      "Tweet 18: 'local conagua vigila una zona de baja presion en el golfo con potencial para desarrollo ciclonico que traera lluvias a partir del domingo a nl'\n",
      "Mejor coincidencia: 'del en' usando 'Del Penon' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 19: 'enterate sectores aledanos a la presa libertad sufren inundaciones generadas por los escurrimientos de las lluvias acumuladas en linares mas informacion en'\n",
      "Mejor coincidencia: 'libertad' usando 'Libertad' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 20: 'enterate tras las lluvias de alberto el gobernador samuel garcia se compromete a arrancar el lunes la reconstruccion de los danos en el par vial'\n",
      "Mejor coincidencia: 'los garcia' usando 'Los Garcia' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 21: 'enterate la conagua reporta que algunas estaciones de medicion alcanzan los milimetros de agua tras las lluvias de la tormenta alberto en nl'\n",
      "Mejor coincidencia: 'las tras' usando 'Las Mitras' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 22: 'local por decadas habitantes de las colonias al norte de monterrey sufrian por las inundaciones ahora sufren por la basura que tapa el drenaje'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 23: 'local luego de su peor nivel en anos las presas que abastecen a la ciudad suben su almacenamiento en conjunto con lluvias de alberto mas informacion en'\n",
      "Mejor coincidencia: 'las las' usando 'Las Selvas' con una puntuación promedio de 83.50\n",
      "\n",
      "Tweet 24: 'local conagua advierte por lluvias fuertes e incluso caida de granizo y actividad electrica en las proximas horas tras degradacion de alberto'\n",
      "Mejor coincidencia: 'las' usando 'Olas' con una puntuación promedio de 86.00\n",
      "\n",
      "Tweet 25: 'enterate la sierra de santiago es impactada por lluvias de la tormenta alberto que dejo deslaves e inundaciones la cola de caballo se desborda mas informacion en'\n",
      "Mejor coincidencia: 'la mas' usando 'Las Damas' con una puntuación promedio de 90.00\n",
      "\n",
      "Tweet 26: 'enterate la fuerza de los afluentes de agua en el parque la huasteca tras las lluvias por alberto rompen la carretera a la presa rompepicos mas informacion en federico padilla'\n",
      "Mejor coincidencia: 'las tras' usando 'Las Mitras' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 27: 'local por decadas habitantes de las colonias al norte de monterrey sufrian por las inundaciones ahora sufren por la basura que tapa el drenaje'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 28: 'local la casa del tec ubicada en santa catarina y que sera rifada este sabado sufre inundaciones por las lluvias de la tormenta alberto mas informacion en'\n",
      "Mejor coincidencia: 'santa catarina' usando 'Santa Catarina' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 29: 'local ayd pide a la poblacion no beber agua de la llave ya que por las recientes lluvias los procesos de purificacion no alcanzan a aclararla'\n",
      "Mejor coincidencia: 'los los' usando 'Los Tilos' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 30: 'enterate las lluvias por la tormenta alberto provocan el cierre de la autopista y la carretera libre de monterrey a saltillo reportan deslaves mas informacion en'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 31: 'local ante lluvias de alberto un tramo del carril expres sobre la avenida constitucion se deslava y cae al rio santa catarina'\n",
      "Mejor coincidencia: 'avenida constitucion' usando 'Avenida Constitucion' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 32: 'local por las fuertes lluvias mas de colonias del sur de monterrey reportan quedarse sin luz desde la madrugada de este jueves'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 33: 'enterate el nivel del rio santa catarina luce con un mayor flujo de agua por las fuertes lluvias que han azotado a la ciudad durante esta madrugada'\n",
      "Mejor coincidencia: 'santa catarina' usando 'Santa Catarina' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 34: No se encontró una coincidencia adecuada.\n",
      "\n",
      "Tweet 35: 'local el rio pilon en montemorelos presenta gran flujo de agua tras las lluvias presentadas durante la tarde al sur del estado mas informacion'\n",
      "Mejor coincidencia: 'rio pilon' usando 'Rio Pilon' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 36: 'local las lluvias provocan fallas en semaforos de la calle zaragoza y en sus cruces con colon y reforma sigue la informacion de las lluvias en el estado aqui'\n",
      "Mejor coincidencia: 'colon' usando 'Colon' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 37: 'enterate la avenida jose angel conchello en monterrey ya sufre los estragos de las lluvias presentadas en la ciudad mas informacion'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 38: 'enterate la llegada de la tormenta alberto comienza a sentirse en la zona metropolitana con lluvias en municipios como monterrey san pedro guadalupe y santa catarina mas informacion'\n",
      "Mejor coincidencia: 'san pedro' usando 'San Pedro' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 39: 'arrecia por lapsos la lluvia en el area metropolitana y rural en nl no tengo dudas el cuchillo y cerro prieto alcanzaran niveles mucho mayores que los actuales'\n",
      "Mejor coincidencia: 'cerro prieto' usando 'Cerro Prieto' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 40: 'niveles de las presas en nl al momento hoy de junio cuando aun faltan lluvias y escurrimientos presa la boca almacenamiento mm presa cerro prieto almacenamiento mm presa el cuchillo almacenamiento mm alberto'\n",
      "Mejor coincidencia: 'cerro prieto' usando 'Cerro Prieto' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 41: 'ahoranl en estos momentos muy fuerte lluvia en avantiguos ejidatarios en la zona de la alianza en monterrey no salgan ni intenten cruzar menos manejar quedense en un lugar seguro loquepasaennl'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 42: 'cierres a la vialidad por inundaciones hasta el momento zona sur camino al mirador y lazaro cardenas parque canoas antiguo camino a villa de santiago y avenida la hacienda antiguo camino a villa de santiago y santa anita'\n",
      "Mejor coincidencia: 'hacienda santa' usando 'Hacienda Santa Maria' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 43: No se encontró una coincidencia adecuada.\n",
      "\n",
      "Tweet 44: 'reportan riesgo de desborde del rio pesqueria en los limites de escobedo y garcia a la altura del libramiento'\n",
      "Mejor coincidencia: 'escobedo' usando 'Escobedo' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 45: 'lamento mucho que didifoodmx didimexico este motivando a sus repartidores a salir a exponer sus vidas con todo y las inundaciones ellos no responderan por la vida de sus repartidores que ni siquiera tienen prestaciones de ley monterrey alberto'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 46: 'continuan las lluvias en la zmm de monterrey por favor extremen precaucionesabimaelsalas andresmijesmx apodacaoficial azucenau cesargarzaarr danielcarrillo eldelaconsty franciscoleonjf gobsannicolas lamiradadeltaxi lcalatorre'\n",
      "Mejor coincidencia: 'monterrey' usando 'Monterrey' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 47: 'y empiezan los memes por la presencia de la lluvia mtyfollow hectorjtrevinot elvazleta berthisbonita elpajonalstacat atentosmtysur eldelaconsty comunidadmitras eduardovarvi judithmedrano'\n",
      "Mejor coincidencia: 'los los' usando 'Los Tilos' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 48: 'todos los regios asi esperando la lluvia del ciclon'\n",
      "Mejor coincidencia: 'los los' usando 'Los Tilos' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 49: 'precaucionvial fidel velazquezbarragan abierto y aforo fluido encharcamientos menores maneje con precaucion saldra el sol por momentos no se confien seguiran lluvias cicmty gobsannicolas camiondesde lilyolivaresc chaledelafuente'\n",
      "Mejor coincidencia: 'fidel' usando 'Fidelio' con una puntuación promedio de 90.00\n",
      "\n",
      "Tweet 50: 'ruta va brindar servicio al menos que digan otra cosa estan checando los recorridos para evitar zonas con cierres o afectadas por la lluvia'\n",
      "Mejor coincidencia: 'servicio al' usando 'Servicio Postal' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 51: No se encontró una coincidencia adecuada.\n",
      "\n",
      "Tweet 52: 'ponteatento con la tormenta evita salir si no es necesario ademas considera que las fuertes lluvias estan afectando algunas vialidades como la carretera linares galeana la autopista monterrey saltillo y la carretera nacional cuidate y extrema precauciones'\n",
      "Mejor coincidencia: 'galeana' usando 'Galeana' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 53: 'prevengamos inundaciones y ayudanos a ser parte de la solucion no tires basura en la calle asi se evita el desbordamientos en las alcantarillas no olvides mantenerte al tanto de las actualizaciones de las fuentes oficiales'\n",
      "Mejor coincidencia: 'calle de' usando 'Calle De Gas' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 54: 'si no es necesario salir de casa mantente a salvo y no salgas ya que las lluvias se incrementaran de forma intensa en el estado'\n",
      "Mejor coincidencia: 'las ya' usando 'Las Tuyas' con una puntuación promedio de 95.00\n",
      "\n",
      "Tweet 55: 'te compartimos algunas recomendaciones emitidas por proteccion civil nuevo leon ante las proximas lluvias no olvides mantenerte al tanto de redes oficiales para cualquier actualizacion'\n",
      "Mejor coincidencia: 'nuevo leon' usando 'Nuevo Leon' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 56: 'informevial elemento de movilidadsn dando apoyo a los trabajo de sofocacion del incendio pcbsn esta trabando para controlado el siniestro cierres viales al momento lopez y caracol lopez y santa rosa dionisio gonzalez y las torres santa rosa y ra avenida gobsannicolas'\n",
      "Mejor coincidencia: 'avenida del' usando 'Avenida del Rio' con una puntuación promedio de 100.00\n",
      "\n",
      "Tweet 57: 'movilidadsn en movilidadsn te damos las siguientes recomendaciones para que puedas evitar accidentes viales gobsannicolas'\n",
      "Mejor coincidencia: 'las las' usando 'Las Selvas' con una puntuación promedio de 83.50\n",
      "\n",
      "Tweet 58: 'buen dia movilidadsn te comparte las siguientes recomendaciones para este dia de lluvia gobsannicolas'\n",
      "Mejor coincidencia: 'las las' usando 'Las Selvas' con una puntuación promedio de 83.50\n",
      "\n",
      "Tweet 59: 'movilidadsn te damos las siguientes recomendaciones para evitar accidentes'\n",
      "Mejor coincidencia: 'las' usando 'Olas' con una puntuación promedio de 86.00\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\process.py:108\u001b[0m, in \u001b[0;36mextractWithoutOrder\u001b[1;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# See if choices is a dictionary-like object.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, choice \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchoices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m    109\u001b[0m         processed \u001b[38;5;241m=\u001b[39m pre_processor(processor(choice))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target_tokens) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     50\u001b[0m     second_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     52\u001b[0m         best_match_token2 \u001b[38;5;241m=\u001b[39m match[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     53\u001b[0m         position2 \u001b[38;5;241m=\u001b[39m tokenized_words\u001b[38;5;241m.\u001b[39mindex(best_match_token2)\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\process.py:168\u001b[0m, in \u001b[0;36mextract\u001b[1;34m(query, choices, processor, scorer, limit)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Select the best match in a list or dictionary of choices.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mFind best matches in a list or dictionary of choices, return a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    [('train', 22, 'bard'), ('man', 0, 'dog')]\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m sl \u001b[38;5;241m=\u001b[39m extractWithoutOrder(query, choices, processor, scorer)\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mheapq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28msorted\u001b[39m(sl, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m i: i[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\heapq.py:563\u001b[0m, in \u001b[0;36mnlargest\u001b[1;34m(n, iterable, key)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# General case, slowest method\u001b[39;00m\n\u001b[0;32m    562\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[1;32m--> 563\u001b[0m result \u001b[38;5;241m=\u001b[39m [(key(elem), i, elem) \u001b[38;5;28;01mfor\u001b[39;00m i, elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39mn, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), it)]\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\heapq.py:563\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# General case, slowest method\u001b[39;00m\n\u001b[0;32m    562\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[1;32m--> 563\u001b[0m result \u001b[38;5;241m=\u001b[39m [(key(elem), i, elem) \u001b[38;5;28;01mfor\u001b[39;00m i, elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39mn, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), it)]\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\process.py:117\u001b[0m, in \u001b[0;36mextractWithoutOrder\u001b[1;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices:\n\u001b[0;32m    116\u001b[0m     processed \u001b[38;5;241m=\u001b[39m pre_processor(processor(choice))\n\u001b[1;32m--> 117\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m score_cutoff:\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (choice, score)\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:276\u001b[0m, in \u001b[0;36mWRatio\u001b[1;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[0;32m    273\u001b[0m unbase_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.95\u001b[39m\n\u001b[0;32m    274\u001b[0m partial_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.90\u001b[39m\n\u001b[1;32m--> 276\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m len_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(p1), \u001b[38;5;28mlen\u001b[39m(p2))) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(p1), \u001b[38;5;28mlen\u001b[39m(p2))\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# if strings are similar length, don't use partials\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\utils.py:29\u001b[0m, in \u001b[0;36mcheck_for_equivalence.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m args[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\utils.py:47\u001b[0m, in \u001b[0;36mcheck_empty_string.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:27\u001b[0m, in \u001b[0;36mratio\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_none\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_equivalence\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_empty_string\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mratio\u001b[39m(s1, s2):\n\u001b[0;32m     25\u001b[0m     s1, s2 \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmake_type_consistent(s1, s2)\n\u001b[1;32m---> 27\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mSequenceMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mintr(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m m\u001b[38;5;241m.\u001b[39mratio())\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\difflib.py:214\u001b[0m, in \u001b[0;36mSequenceMatcher.__init__\u001b[1;34m(self, isjunk, a, b, autojunk)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautojunk \u001b[38;5;241m=\u001b[39m autojunk\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\difflib.py:226\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seqs\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set the two sequences to be compared.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m>>> s = SequenceMatcher()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m0.75\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_seq1(a)\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seq2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\difflib.py:280\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seq2\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatching_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopcodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullbcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__chain_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\difflib.py:317\u001b[0m, in \u001b[0;36mSequenceMatcher.__chain_b\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m     indices\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# Purge junk elements\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbjunk\u001b[49m \u001b[38;5;241m=\u001b[39m junk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    318\u001b[0m isjunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misjunk\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isjunk:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Inicializar el tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Cargar los datos desde los archivos CSV\n",
    "#calles_df = pd.read_csv('calles_colonias_monterrey.csv')\n",
    "#tweets_df = pd.read_csv('tweets_classified.csv')\n",
    "\n",
    "# Definir el umbral de similitud\n",
    "similarity_threshold = 80  # Ajusta este valor según lo que consideres adecuado\n",
    "\n",
    "# Iterar sobre cada tweet\n",
    "for tweet_index, tweet_row in tweets_df.iterrows():\n",
    "    text = tweet_row['Texto']\n",
    "\n",
    "    # Tokenizar el texto del tweet\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokenized_words = tokenizer.convert_tokens_to_string(tokens).split()\n",
    "\n",
    "    best_overall_match = None\n",
    "    best_matched_phrase = \"\"\n",
    "    best_target_word = \"\"\n",
    "\n",
    "    # Iterar sobre cada palabra objetivo\n",
    "    for _, calle_row in calles_df.iterrows():\n",
    "        target_word = calle_row['name']\n",
    "        target_tokens = target_word.split()\n",
    "\n",
    "        if len(tokenized_words) < len(target_tokens):\n",
    "            continue  # Saltar si el tweet no tiene suficientes palabras tokenizadas\n",
    "\n",
    "        # Buscar coincidencia para la primera token\n",
    "        first_match = process.extractOne(target_tokens[0], tokenized_words)\n",
    "        best_match_token1 = first_match[0]\n",
    "        position1 = tokenized_words.index(best_match_token1)\n",
    "\n",
    "        # Encontrar la palabra original en el texto para la primera token\n",
    "        original_word1 = \"\"\n",
    "        for word in text.split():\n",
    "            if best_match_token1.lower() in word.lower():\n",
    "                original_word1 = word\n",
    "                break\n",
    "\n",
    "        # Buscar coincidencia para la segunda token cercana a la primera (si existe)\n",
    "        if len(target_tokens) > 1:\n",
    "            second_match = None\n",
    "            for match in process.extract(target_tokens[1], tokenized_words, limit=5):\n",
    "                best_match_token2 = match[0]\n",
    "                position2 = tokenized_words.index(best_match_token2)\n",
    "                if abs(position2 - position1) <= len(target_word.split()):\n",
    "                    second_match = match\n",
    "                    break\n",
    "\n",
    "            # Si no se encuentra una coincidencia cercana para la segunda token\n",
    "            if second_match is None:\n",
    "                # Buscar la mejor coincidencia sin importar la proximidad\n",
    "                second_match = process.extractOne(target_tokens[1], tokenized_words)\n",
    "                best_match_token2 = second_match[0]\n",
    "                position2 = tokenized_words.index(best_match_token2)\n",
    "\n",
    "            # Encontrar las palabras originales en el texto para la segunda token\n",
    "            original_word2 = \"\"\n",
    "            for word in text.split():\n",
    "                if best_match_token2.lower() in word.lower():\n",
    "                    original_word2 = word\n",
    "                    break\n",
    "\n",
    "            # Unir las palabras originales para obtener la frase final\n",
    "            matched_phrase = f\"{original_word1} {original_word2}\".strip()\n",
    "            average_score = (first_match[1] + second_match[1]) / 2\n",
    "        else:\n",
    "            matched_phrase = original_word1\n",
    "            average_score = first_match[1]\n",
    "\n",
    "        # Evitar coincidencias de frases que no tienen sentido (ej. \"del el\")\n",
    "        if any(word not in target_word.lower() for word in matched_phrase.lower().split()):\n",
    "            continue\n",
    "\n",
    "        # Comparar la coincidencia encontrada con la palabra objetivo usando FuzzyWuzzy\n",
    "        similarity_score = fuzz.ratio(matched_phrase.lower(), target_word.lower())\n",
    "\n",
    "        # Verificar si la similitud es mayor que el umbral definido\n",
    "        if similarity_score >= similarity_threshold:\n",
    "            # Comparar con la mejor coincidencia encontrada hasta ahora\n",
    "            if best_overall_match is None or average_score > best_overall_match:\n",
    "                best_overall_match = average_score\n",
    "                best_matched_phrase = matched_phrase\n",
    "                best_target_word = target_word\n",
    "\n",
    "    if best_matched_phrase:\n",
    "        print(f\"Tweet {tweet_index}: '{text}'\")\n",
    "        print(f\"Mejor coincidencia: '{best_matched_phrase}' usando '{best_target_word}' con una puntuación promedio de {best_overall_match:.2f}\\n\")\n",
    "    else:\n",
    "        print(f\"Tweet {tweet_index}: No se encontró una coincidencia adecuada.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

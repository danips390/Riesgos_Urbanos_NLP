{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels\n",
      "Labels created\n",
      "Analyzing coincidences\n",
      "Fila 0: Reemplazando 'monterrey' por 'Monterrey' con 100% de similitud\n",
      "Fila 0: Reemplazando 'villaflorida' por 'VILLA FLORIDA' con 100% de similitud\n",
      "Fila 1: Reemplazando 'delvalle' por 'DEL VALLE' con 100% de similitud\n",
      "Fila 0: Reemplazando 'eugeniogarzasada' por 'Avenida Eugenio Garza Sada' con 100% de similitud\n",
      "Fila 0: Reemplazando 'avdelestado' por 'Avenida del Estado' con 90% de similitud\n",
      "Fila 1: No se encontró coincidencia suficiente para 'riomisisipi' (Similitud: 64%)\n",
      "Process finished. Fuzzy dataframe created.\n"
     ]
    }
   ],
   "source": [
    "import Model2Fuzzy as mf\n",
    "import pandas as pd\n",
    "import spacy\n",
    "# Texto que deseas poner en el DataFrame\n",
    "texto1 = \"se produce una inundación en ave garza sada y av del estado, cerca de la colonia villa florida en mty, nl, bomberosmty\"\n",
    "texto2 = \"precaucion por lluvias fuertes en la colonia del valle y la calle rio misisipi\"\n",
    "# Crear un DataFrame con una columna de texto\n",
    "df = pd.DataFrame({'Texto': [texto1, texto2]})\n",
    "\n",
    "\n",
    "lables = [\"COL\", \"CALLE\", \"MUN\", \"REGION\"]\n",
    "model = spacy.load(\"fuzzymodelV1_0_2\")\n",
    "outputname = \"text.csv\"\n",
    "newdf = mf.CreateLabels(model, df, \"Texto\", lables, outputname)\n",
    "newdf = pd.read_csv(outputname)\n",
    "\n",
    "colIterableNames = [\"municipio\", \"colonia\", \"calle\"]\n",
    "realData = pd.read_csv(\"DataMTY.csv\")\n",
    "outputname = \"textGOD1.csv\"\n",
    "testdf = mf.Fuzzy2Result(newdf, realData, colIterableNames, outputname)\n",
    "testdf = pd.read_csv(outputname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'tweets_classified.csv' guardado con las etiquetas predichas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "# Cargar el tokenizador y el modelo\n",
    "tokenizer = BertTokenizer.from_pretrained('./class_my_model')\n",
    "model = BertForSequenceClassification.from_pretrained('./class_my_model')\n",
    "\n",
    "# Cargar el LabelEncoder (Asegúrate de que es el mismo usado durante el entrenamiento)\n",
    "df_original = pd.read_csv(\"tweets_better_classified.csv\")  # Dataset original para recuperar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_original['Tipo'])  # Ajusta 'Tipo' a la columna de etiquetas original\n",
    "\n",
    "# Cargar el dataset filtrado\n",
    "df_filtered = pd.read_csv(\"textGOD1.csv\")\n",
    "\n",
    "# Define una función para predecir nuevos textos\n",
    "def predict_new_text(text):\n",
    "    # Tokenizar el texto\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # Asegúrate de mover el modelo y los inputs a la GPU si está disponible\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Hacer la predicción\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Obtener la clase predicha\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    # Decodificar la etiqueta predicha\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class])\n",
    "\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Predecir etiquetas para la columna 'texto' y almacenarlas en una nueva columna 'Tipo'\n",
    "df_filtered['Tipo'] = df_filtered['Texto'].apply(predict_new_text)\n",
    "\n",
    "# Guardar el nuevo DataFrame en un archivo CSV\n",
    "df_filtered.to_csv(\"textGOD2.csv\", index=False)\n",
    "\n",
    "print(\"Archivo 'tweets_classified.csv' guardado con las etiquetas predichas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lol_a\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "# Cambia el modelo a uno adecuado para español\n",
    "MODEL = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Lee el archivo CSV\n",
    "file_path = 'textGOD2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Asignación de valores a las etiquetas de sentimiento\n",
    "sentiment_labels = [-2, -1, 0, 1, 2]\n",
    "\n",
    "# Función para calcular la puntuación de sentimiento\n",
    "def calculate_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    scores = outputs.logits.detach().numpy()\n",
    "    scores = softmax(scores[0])\n",
    "    sentiment_score = sum([a*b for a, b in zip(sentiment_labels, scores)])\n",
    "    return sentiment_score\n",
    "\n",
    "# Aplicar la función a cada texto en la columna 'Texto'\n",
    "df['Puntaje'] = df['Texto'].apply(calculate_sentiment)\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el dataset modificado en un nuevo archivo CSV\n",
    "output_path = 'textGOD3.csv' \n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lol_a\\AppData\\Local\\Temp\\ipykernel_22200\\3035917485.py:71: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap_municipios = cm.get_cmap('RdYlGn')\n",
      "C:\\Users\\lol_a\\AppData\\Local\\Temp\\ipykernel_22200\\3035917485.py:102: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap_colonias = cm.get_cmap('RdYlGn')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa guardado como 'mapa4.html'.\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import ast\n",
    "\n",
    "def safe_convert_to_list(value):\n",
    "    \"\"\"\n",
    "    Convierte un valor de texto que parece una lista en una lista de Python.\n",
    "    Si ya es una lista, la devuelve tal cual.\n",
    "    Si no es posible convertirlo, devuelve una lista vacía.\n",
    "    \"\"\"\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            # Intentar convertir la cadena a una lista si tiene el formato adecuado\n",
    "            return ast.literal_eval(value)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # Si no es posible, devolver una lista vacía\n",
    "            return [value]  # Devolver la cadena como un elemento en la lista\n",
    "    return []\n",
    "\n",
    "# Inicializar el geocodificador\n",
    "geolocator = Nominatim(user_agent=\"mi_aplicacion_mapa\")\n",
    "\n",
    "# Cargar el archivo SHP de municipios\n",
    "shapefile_municipios = r\"2023_1_19_A\\2023_1_19_A.shp\"\n",
    "gdf_municipios = gpd.read_file(shapefile_municipios)\n",
    "\n",
    "# Cargar el archivo SHP de colonias\n",
    "shapefile_colonias = r\"Colonias\\Colonias.shp\"\n",
    "gdf_colonias = gpd.read_file(shapefile_colonias)\n",
    "gdf_colonias = gdf_colonias[gdf_colonias[\"ST_NAME\"] == \"NUEVO LEON\"]\n",
    "\n",
    "# Cargar el DataFrame principal con los datos desde B_testDf.csv\n",
    "df_calles = pd.read_csv(\"textGOD3.csv\")\n",
    "\n",
    "# Excluir los municipios \"Monte Morelos\" y \"Saltillo\"\n",
    "df_calles = df_calles[~df_calles['municipio'].isin(['monte morelos', 'saltillo'])]\n",
    "\n",
    "# Filtrar los municipios y calcular el puntaje promedio por municipio\n",
    "cve_mun_values = {\n",
    "    '006': 'apodaca',\n",
    "    '019': 'san pedro garza garcía',\n",
    "    '021': 'escobedo',\n",
    "    '026': 'guadalupe',\n",
    "    '039': 'monterrey',\n",
    "    '046': 'san nicolás',\n",
    "    '048': 'santa catarina',\n",
    "    '049': 'santiago'\n",
    "}\n",
    "\n",
    "promedio_puntajes_municipios = {}\n",
    "for cve, municipio in cve_mun_values.items():\n",
    "    filas_municipio = df_calles[df_calles['municipio'].str.lower() == municipio.lower()]\n",
    "    if not filas_municipio.empty:\n",
    "        promedio_puntajes_municipios[cve] = np.mean(filas_municipio['Puntaje'])\n",
    "    else:\n",
    "        promedio_puntajes_municipios[cve] = None\n",
    "\n",
    "# Asignar los puntajes promedios a los códigos CVE_MUN correspondientes\n",
    "gdf_municipios['Puntaje'] = gdf_municipios['CVE_MUN'].map(promedio_puntajes_municipios)\n",
    "\n",
    "# Configurar el colormap para municipios\n",
    "norm_municipios = Normalize(vmin=-2, vmax=2)\n",
    "cmap_municipios = cm.get_cmap('RdYlGn')\n",
    "\n",
    "# Crear el mapa centrado en Monterrey\n",
    "mapa = folium.Map(location=[25.6866, -100.3161], zoom_start=13)\n",
    "\n",
    "# Crear capas para municipios, colonias y calles\n",
    "municipios_layer = folium.FeatureGroup(name='Municipios')\n",
    "colonias_layer = folium.FeatureGroup(name='Colonias')\n",
    "calles_layer = folium.FeatureGroup(name='Calles')  # Nueva capa para las calles\n",
    "\n",
    "# Añadir los polígonos de municipios al mapa\n",
    "for _, row in gdf_municipios.iterrows():\n",
    "    puntaje = row['Puntaje']\n",
    "    if puntaje is not None:\n",
    "        color = cmap_municipios(norm_municipios(puntaje))[:3]\n",
    "        color = [int(c * 255) for c in color]\n",
    "        folium.GeoJson(\n",
    "            row['geometry'],\n",
    "            style_function=lambda x, color=color: {\n",
    "                'fillColor': f'rgba({color[0]}, {color[1]}, {color[2]}, 0.6)',\n",
    "                'color': 'black',\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.6,\n",
    "            }\n",
    "        ).add_to(municipios_layer)\n",
    "\n",
    "# Añadir los polígonos de colonias al mapa\n",
    "df_calles['colonia'] = df_calles['colonia'].astype(str).str.upper()\n",
    "gdf_colonias = gdf_colonias.merge(df_calles, left_on='SETT_NAME', right_on='colonia', how='left')\n",
    "\n",
    "norm_colonias = Normalize(vmin=df_calles['Puntaje'].min(), vmax=df_calles['Puntaje'].max())\n",
    "cmap_colonias = cm.get_cmap('RdYlGn')\n",
    "\n",
    "for _, row in gdf_colonias.iterrows():\n",
    "    puntaje = row['Puntaje']\n",
    "    if puntaje is not None:\n",
    "        color = cmap_colonias(norm_colonias(puntaje))[:3]\n",
    "        color = [int(c * 255) for c in color]\n",
    "        folium.GeoJson(\n",
    "            row['geometry'],\n",
    "            style_function=lambda x, color=color: {\n",
    "                'fillColor': f'rgba({color[0]}, {color[1]}, {color[2]}, 0.6)',\n",
    "                'color': 'black',\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.4,\n",
    "            }\n",
    "        ).add_to(colonias_layer)\n",
    "\n",
    "# Lista de municipios a probar en caso de que no se encuentre la calle en Monterrey\n",
    "municipios_lista = ['Monterrey', 'Apodaca', 'San Pedro Garza García', 'Escobedo', 'Guadalupe', 'San Nicolás', 'Santa Catarina', 'Santiago']\n",
    "\n",
    "# Iterar sobre las calles y listas de calles\n",
    "for idx, row in df_calles.iterrows():\n",
    "    calles_lista = row['calle']\n",
    "    puntaje = row['Puntaje']  # Obtener el puntaje de la calle\n",
    "    tipo = row['Tipo']  # Obtener la clasificación de la calle\n",
    "    \n",
    "    # Definir el ícono y el color según el tipo de calle\n",
    "    if tipo.lower() == 'lluvia':\n",
    "        icono = \"cloud\"\n",
    "        color_icono = \"blue\"\n",
    "    elif tipo.lower() == 'inundación':\n",
    "        icono = \"tint\"\n",
    "        color_icono = \"red\"\n",
    "    elif tipo.lower() == 'eléctrico':\n",
    "        icono = \"flash\"  # Cambiado a 'flash' ya que 'plug' no está disponible\n",
    "        color_icono = \"orange\"\n",
    "    else:\n",
    "        icono = \"question-circle\"\n",
    "        color_icono = \"gray\"  # Color para los tipos no relacionados\n",
    "    \n",
    "    # Asegurarse de que el valor de 'calle' es una cadena\n",
    "    if isinstance(calles_lista, str):\n",
    "        # Dividir por comas en caso de que haya más de una calle en la celda\n",
    "        calles_lista = [calle.strip() for calle in calles_lista.split(',')]\n",
    "    \n",
    "    # Iterar sobre la lista de calles y geolocalizarlas\n",
    "    if isinstance(calles_lista, list) and calles_lista:\n",
    "        for calle in calles_lista:\n",
    "            if calle:  # Asegurarse de que la calle no esté vacía\n",
    "                found_location = False\n",
    "                for municipio in municipios_lista:\n",
    "                    try:\n",
    "                        # Intentar geolocalizar la calle\n",
    "                        location = geolocator.geocode(calle + \", \" + municipio + \", Mexico\")\n",
    "                        time.sleep(1)  # Evitar sobrecarga del servicio\n",
    "                        if location:\n",
    "                            # Crear popup con información de la calle\n",
    "                            popup_text = f\"<b>Calle:</b> {calle}<br><b>Puntaje:</b> {puntaje}<br><b>Clasificación:</b> {tipo}\"\n",
    "                            # Añadir el marcador con el ícono correspondiente\n",
    "                            folium.Marker(\n",
    "                                location=[location.latitude, location.longitude],\n",
    "                                popup=popup_text,\n",
    "                                icon=folium.Icon(icon=icono, color=color_icono),  # Añadir ícono y color según la clasificación\n",
    "                            ).add_to(calles_layer)  # Añadir marcador a la capa de calles\n",
    "                            found_location = True\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al intentar obtener las coordenadas para {calle} en {municipio}: {e}\")\n",
    "                \n",
    "                if not found_location:\n",
    "                    print(f\"No se encontraron coordenadas para {calle} en ningún municipio.\")\n",
    "\n",
    "# Añadir las capas al mapa\n",
    "mapa.add_child(municipios_layer)\n",
    "mapa.add_child(colonias_layer)\n",
    "mapa.add_child(calles_layer)  # Añadir la capa de calles\n",
    "\n",
    "# Añadir control de capas\n",
    "folium.LayerControl().add_to(mapa)\n",
    "\n",
    "# Guardar el mapa como archivo HTML\n",
    "mapa.save(\"mapa4.html\")\n",
    "\n",
    "print(\"Mapa guardado como 'mapa4.html'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
